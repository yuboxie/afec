{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from datetime import timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl Submissions from r/TodayIamHappy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00 1577836800.0\n"
     ]
    }
   ],
   "source": [
    "end_date = datetime(2020, 1, 1)\n",
    "end_timestamp = end_date.replace(tzinfo = timezone.utc).timestamp()\n",
    "print(end_date, end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-17 00:00:00 1550361600.0\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime(2019, 2, 17)\n",
    "start_timestamp = start_date.replace(tzinfo = timezone.utc).timestamp()\n",
    "print(start_date, start_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_cols = ['id', 'created_utc', 'title', 'selftext', 'num_comments', 'subreddit', 'subreddit_id']\n",
    "submission_cols_opt = ['score', 'author_fullname', 'link_flair_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {col: [] for col in submission_cols + submission_cols_opt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_json(json_data):\n",
    "    try:\n",
    "        json_object = json.loads(json_data)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling from 2019-12-31 00:00:00+00:00 to 2020-01-01 00:00:00+00:00...\n",
      "Crawling from 2019-12-30 00:00:00+00:00 to 2019-12-31 00:00:00+00:00...\n",
      "Crawling from 2019-12-29 00:00:00+00:00 to 2019-12-30 00:00:00+00:00...\n",
      "Crawling from 2019-12-28 00:00:00+00:00 to 2019-12-29 00:00:00+00:00...\n",
      "Crawling from 2019-12-27 00:00:00+00:00 to 2019-12-28 00:00:00+00:00...\n",
      "Crawling from 2019-12-26 00:00:00+00:00 to 2019-12-27 00:00:00+00:00...\n",
      "Crawling from 2019-12-25 00:00:00+00:00 to 2019-12-26 00:00:00+00:00...\n",
      "Crawling from 2019-12-24 00:00:00+00:00 to 2019-12-25 00:00:00+00:00...\n",
      "Crawling from 2019-12-23 00:00:00+00:00 to 2019-12-24 00:00:00+00:00...\n",
      "Crawling from 2019-12-22 00:00:00+00:00 to 2019-12-23 00:00:00+00:00...\n",
      "Crawling from 2019-12-21 00:00:00+00:00 to 2019-12-22 00:00:00+00:00...\n",
      "Crawling from 2019-12-20 00:00:00+00:00 to 2019-12-21 00:00:00+00:00...\n",
      "Crawling from 2019-12-19 00:00:00+00:00 to 2019-12-20 00:00:00+00:00...\n",
      "Crawling from 2019-12-18 00:00:00+00:00 to 2019-12-19 00:00:00+00:00...\n",
      "Crawling from 2019-12-17 00:00:00+00:00 to 2019-12-18 00:00:00+00:00...\n",
      "Crawling from 2019-12-16 00:00:00+00:00 to 2019-12-17 00:00:00+00:00...\n",
      "Crawling from 2019-12-15 00:00:00+00:00 to 2019-12-16 00:00:00+00:00...\n",
      "Crawling from 2019-12-14 00:00:00+00:00 to 2019-12-15 00:00:00+00:00...\n",
      "Crawling from 2019-12-13 00:00:00+00:00 to 2019-12-14 00:00:00+00:00...\n",
      "Crawling from 2019-12-12 00:00:00+00:00 to 2019-12-13 00:00:00+00:00...\n",
      "Crawling from 2019-12-11 00:00:00+00:00 to 2019-12-12 00:00:00+00:00...\n",
      "Crawling from 2019-12-10 00:00:00+00:00 to 2019-12-11 00:00:00+00:00...\n",
      "Crawling from 2019-12-09 00:00:00+00:00 to 2019-12-10 00:00:00+00:00...\n",
      "Crawling from 2019-12-08 00:00:00+00:00 to 2019-12-09 00:00:00+00:00...\n",
      "Crawling from 2019-12-07 00:00:00+00:00 to 2019-12-08 00:00:00+00:00...\n",
      "Crawling from 2019-12-06 00:00:00+00:00 to 2019-12-07 00:00:00+00:00...\n",
      "Crawling from 2019-12-05 00:00:00+00:00 to 2019-12-06 00:00:00+00:00...\n",
      "Crawling from 2019-12-04 00:00:00+00:00 to 2019-12-05 00:00:00+00:00...\n",
      "Crawling from 2019-12-03 00:00:00+00:00 to 2019-12-04 00:00:00+00:00...\n",
      "Crawling from 2019-12-02 00:00:00+00:00 to 2019-12-03 00:00:00+00:00...\n",
      "Crawling from 2019-12-01 00:00:00+00:00 to 2019-12-02 00:00:00+00:00...\n",
      "Crawling from 2019-11-30 00:00:00+00:00 to 2019-12-01 00:00:00+00:00...\n",
      "Crawling from 2019-11-29 00:00:00+00:00 to 2019-11-30 00:00:00+00:00...\n",
      "Crawling from 2019-11-28 00:00:00+00:00 to 2019-11-29 00:00:00+00:00...\n",
      "Crawling from 2019-11-27 00:00:00+00:00 to 2019-11-28 00:00:00+00:00...\n",
      "Crawling from 2019-11-26 00:00:00+00:00 to 2019-11-27 00:00:00+00:00...\n",
      "Crawling from 2019-11-25 00:00:00+00:00 to 2019-11-26 00:00:00+00:00...\n",
      "Crawling from 2019-11-24 00:00:00+00:00 to 2019-11-25 00:00:00+00:00...\n",
      "Crawling from 2019-11-23 00:00:00+00:00 to 2019-11-24 00:00:00+00:00...\n",
      "Crawling from 2019-11-22 00:00:00+00:00 to 2019-11-23 00:00:00+00:00...\n",
      "Crawling from 2019-11-21 00:00:00+00:00 to 2019-11-22 00:00:00+00:00...\n",
      "Crawling from 2019-11-20 00:00:00+00:00 to 2019-11-21 00:00:00+00:00...\n",
      "Crawling from 2019-11-19 00:00:00+00:00 to 2019-11-20 00:00:00+00:00...\n",
      "Crawling from 2019-11-18 00:00:00+00:00 to 2019-11-19 00:00:00+00:00...\n",
      "Crawling from 2019-11-17 00:00:00+00:00 to 2019-11-18 00:00:00+00:00...\n",
      "Crawling from 2019-11-16 00:00:00+00:00 to 2019-11-17 00:00:00+00:00...\n",
      "Crawling from 2019-11-15 00:00:00+00:00 to 2019-11-16 00:00:00+00:00...\n",
      "Crawling from 2019-11-14 00:00:00+00:00 to 2019-11-15 00:00:00+00:00...\n",
      "Crawling from 2019-11-13 00:00:00+00:00 to 2019-11-14 00:00:00+00:00...\n",
      "Crawling from 2019-11-12 00:00:00+00:00 to 2019-11-13 00:00:00+00:00...\n",
      "Crawling from 2019-11-11 00:00:00+00:00 to 2019-11-12 00:00:00+00:00...\n",
      "Crawling from 2019-11-10 00:00:00+00:00 to 2019-11-11 00:00:00+00:00...\n",
      "Crawling from 2019-11-09 00:00:00+00:00 to 2019-11-10 00:00:00+00:00...\n",
      "Crawling from 2019-11-08 00:00:00+00:00 to 2019-11-09 00:00:00+00:00...\n",
      "Crawling from 2019-11-07 00:00:00+00:00 to 2019-11-08 00:00:00+00:00...\n",
      "Crawling from 2019-11-06 00:00:00+00:00 to 2019-11-07 00:00:00+00:00...\n",
      "Crawling from 2019-11-05 00:00:00+00:00 to 2019-11-06 00:00:00+00:00...\n",
      "Crawling from 2019-11-04 00:00:00+00:00 to 2019-11-05 00:00:00+00:00...\n",
      "Crawling from 2019-11-03 00:00:00+00:00 to 2019-11-04 00:00:00+00:00...\n",
      "Crawling from 2019-11-02 00:00:00+00:00 to 2019-11-03 00:00:00+00:00...\n",
      "Crawling from 2019-11-01 00:00:00+00:00 to 2019-11-02 00:00:00+00:00...\n",
      "Crawling from 2019-10-31 00:00:00+00:00 to 2019-11-01 00:00:00+00:00...\n",
      "Crawling from 2019-10-30 00:00:00+00:00 to 2019-10-31 00:00:00+00:00...\n",
      "Crawling from 2019-10-29 00:00:00+00:00 to 2019-10-30 00:00:00+00:00...\n",
      "Crawling from 2019-10-28 00:00:00+00:00 to 2019-10-29 00:00:00+00:00...\n",
      "Crawling from 2019-10-27 00:00:00+00:00 to 2019-10-28 00:00:00+00:00...\n",
      "Crawling from 2019-10-26 00:00:00+00:00 to 2019-10-27 00:00:00+00:00...\n",
      "Crawling from 2019-10-25 00:00:00+00:00 to 2019-10-26 00:00:00+00:00...\n",
      "Crawling from 2019-10-24 00:00:00+00:00 to 2019-10-25 00:00:00+00:00...\n",
      "Crawling from 2019-10-23 00:00:00+00:00 to 2019-10-24 00:00:00+00:00...\n",
      "Crawling from 2019-10-22 00:00:00+00:00 to 2019-10-23 00:00:00+00:00...\n",
      "Crawling from 2019-10-21 00:00:00+00:00 to 2019-10-22 00:00:00+00:00...\n",
      "Crawling from 2019-10-20 00:00:00+00:00 to 2019-10-21 00:00:00+00:00...\n",
      "Crawling from 2019-10-19 00:00:00+00:00 to 2019-10-20 00:00:00+00:00...\n",
      "Crawling from 2019-10-18 00:00:00+00:00 to 2019-10-19 00:00:00+00:00...\n",
      "Crawling from 2019-10-17 00:00:00+00:00 to 2019-10-18 00:00:00+00:00...\n",
      "Crawling from 2019-10-16 00:00:00+00:00 to 2019-10-17 00:00:00+00:00...\n",
      "Crawling from 2019-10-15 00:00:00+00:00 to 2019-10-16 00:00:00+00:00...\n",
      "Crawling from 2019-10-14 00:00:00+00:00 to 2019-10-15 00:00:00+00:00...\n",
      "Crawling from 2019-10-13 00:00:00+00:00 to 2019-10-14 00:00:00+00:00...\n",
      "Crawling from 2019-10-12 00:00:00+00:00 to 2019-10-13 00:00:00+00:00...\n",
      "Crawling from 2019-10-11 00:00:00+00:00 to 2019-10-12 00:00:00+00:00...\n",
      "Crawling from 2019-10-10 00:00:00+00:00 to 2019-10-11 00:00:00+00:00...\n",
      "Crawling from 2019-10-09 00:00:00+00:00 to 2019-10-10 00:00:00+00:00...\n",
      "Crawling from 2019-10-08 00:00:00+00:00 to 2019-10-09 00:00:00+00:00...\n",
      "Crawling from 2019-10-07 00:00:00+00:00 to 2019-10-08 00:00:00+00:00...\n",
      "Crawling from 2019-10-06 00:00:00+00:00 to 2019-10-07 00:00:00+00:00...\n",
      "Crawling from 2019-10-05 00:00:00+00:00 to 2019-10-06 00:00:00+00:00...\n",
      "Crawling from 2019-10-04 00:00:00+00:00 to 2019-10-05 00:00:00+00:00...\n",
      "Crawling from 2019-10-03 00:00:00+00:00 to 2019-10-04 00:00:00+00:00...\n",
      "Crawling from 2019-10-02 00:00:00+00:00 to 2019-10-03 00:00:00+00:00...\n",
      "Crawling from 2019-10-01 00:00:00+00:00 to 2019-10-02 00:00:00+00:00...\n",
      "Crawling from 2019-09-30 00:00:00+00:00 to 2019-10-01 00:00:00+00:00...\n",
      "Crawling from 2019-09-29 00:00:00+00:00 to 2019-09-30 00:00:00+00:00...\n",
      "Crawling from 2019-09-28 00:00:00+00:00 to 2019-09-29 00:00:00+00:00...\n",
      "Crawling from 2019-09-27 00:00:00+00:00 to 2019-09-28 00:00:00+00:00...\n",
      "Crawling from 2019-09-26 00:00:00+00:00 to 2019-09-27 00:00:00+00:00...\n",
      "Crawling from 2019-09-25 00:00:00+00:00 to 2019-09-26 00:00:00+00:00...\n",
      "Crawling from 2019-09-24 00:00:00+00:00 to 2019-09-25 00:00:00+00:00...\n",
      "Crawling from 2019-09-23 00:00:00+00:00 to 2019-09-24 00:00:00+00:00...\n",
      "Crawling from 2019-09-22 00:00:00+00:00 to 2019-09-23 00:00:00+00:00...\n",
      "Crawling from 2019-09-21 00:00:00+00:00 to 2019-09-22 00:00:00+00:00...\n",
      "Crawling from 2019-09-20 00:00:00+00:00 to 2019-09-21 00:00:00+00:00...\n",
      "Crawling from 2019-09-19 00:00:00+00:00 to 2019-09-20 00:00:00+00:00...\n",
      "Crawling from 2019-09-18 00:00:00+00:00 to 2019-09-19 00:00:00+00:00...\n",
      "Crawling from 2019-09-17 00:00:00+00:00 to 2019-09-18 00:00:00+00:00...\n",
      "Crawling from 2019-09-16 00:00:00+00:00 to 2019-09-17 00:00:00+00:00...\n",
      "Crawling from 2019-09-15 00:00:00+00:00 to 2019-09-16 00:00:00+00:00...\n",
      "Crawling from 2019-09-14 00:00:00+00:00 to 2019-09-15 00:00:00+00:00...\n",
      "Crawling from 2019-09-13 00:00:00+00:00 to 2019-09-14 00:00:00+00:00...\n",
      "Crawling from 2019-09-12 00:00:00+00:00 to 2019-09-13 00:00:00+00:00...\n",
      "Crawling from 2019-09-11 00:00:00+00:00 to 2019-09-12 00:00:00+00:00...\n",
      "Crawling from 2019-09-10 00:00:00+00:00 to 2019-09-11 00:00:00+00:00...\n",
      "Crawling from 2019-09-09 00:00:00+00:00 to 2019-09-10 00:00:00+00:00...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling from 2019-09-08 00:00:00+00:00 to 2019-09-09 00:00:00+00:00...\n",
      "Crawling from 2019-09-07 00:00:00+00:00 to 2019-09-08 00:00:00+00:00...\n",
      "Crawling from 2019-09-06 00:00:00+00:00 to 2019-09-07 00:00:00+00:00...\n",
      "Crawling from 2019-09-05 00:00:00+00:00 to 2019-09-06 00:00:00+00:00...\n",
      "Crawling from 2019-09-04 00:00:00+00:00 to 2019-09-05 00:00:00+00:00...\n",
      "Crawling from 2019-09-03 00:00:00+00:00 to 2019-09-04 00:00:00+00:00...\n",
      "Crawling from 2019-09-02 00:00:00+00:00 to 2019-09-03 00:00:00+00:00...\n",
      "Crawling from 2019-09-01 00:00:00+00:00 to 2019-09-02 00:00:00+00:00...\n",
      "Crawling from 2019-08-31 00:00:00+00:00 to 2019-09-01 00:00:00+00:00...\n",
      "Crawling from 2019-08-30 00:00:00+00:00 to 2019-08-31 00:00:00+00:00...\n",
      "Crawling from 2019-08-29 00:00:00+00:00 to 2019-08-30 00:00:00+00:00...\n",
      "Crawling from 2019-08-28 00:00:00+00:00 to 2019-08-29 00:00:00+00:00...\n",
      "Crawling from 2019-08-27 00:00:00+00:00 to 2019-08-28 00:00:00+00:00...\n",
      "Crawling from 2019-08-26 00:00:00+00:00 to 2019-08-27 00:00:00+00:00...\n",
      "Crawling from 2019-08-25 00:00:00+00:00 to 2019-08-26 00:00:00+00:00...\n",
      "Crawling from 2019-08-24 00:00:00+00:00 to 2019-08-25 00:00:00+00:00...\n",
      "Crawling from 2019-08-23 00:00:00+00:00 to 2019-08-24 00:00:00+00:00...\n",
      "Crawling from 2019-08-22 00:00:00+00:00 to 2019-08-23 00:00:00+00:00...\n",
      "Crawling from 2019-08-21 00:00:00+00:00 to 2019-08-22 00:00:00+00:00...\n",
      "Crawling from 2019-08-20 00:00:00+00:00 to 2019-08-21 00:00:00+00:00...\n",
      "Crawling from 2019-08-19 00:00:00+00:00 to 2019-08-20 00:00:00+00:00...\n",
      "Crawling from 2019-08-18 00:00:00+00:00 to 2019-08-19 00:00:00+00:00...\n",
      "Crawling from 2019-08-17 00:00:00+00:00 to 2019-08-18 00:00:00+00:00...\n",
      "Crawling from 2019-08-16 00:00:00+00:00 to 2019-08-17 00:00:00+00:00...\n",
      "Crawling from 2019-08-15 00:00:00+00:00 to 2019-08-16 00:00:00+00:00...\n",
      "Crawling from 2019-08-14 00:00:00+00:00 to 2019-08-15 00:00:00+00:00...\n",
      "Crawling from 2019-08-13 00:00:00+00:00 to 2019-08-14 00:00:00+00:00...\n",
      "Crawling from 2019-08-12 00:00:00+00:00 to 2019-08-13 00:00:00+00:00...\n",
      "Crawling from 2019-08-11 00:00:00+00:00 to 2019-08-12 00:00:00+00:00...\n",
      "Crawling from 2019-08-10 00:00:00+00:00 to 2019-08-11 00:00:00+00:00...\n",
      "Crawling from 2019-08-09 00:00:00+00:00 to 2019-08-10 00:00:00+00:00...\n",
      "Crawling from 2019-08-08 00:00:00+00:00 to 2019-08-09 00:00:00+00:00...\n",
      "Crawling from 2019-08-07 00:00:00+00:00 to 2019-08-08 00:00:00+00:00...\n",
      "Crawling from 2019-08-06 00:00:00+00:00 to 2019-08-07 00:00:00+00:00...\n",
      "Crawling from 2019-08-05 00:00:00+00:00 to 2019-08-06 00:00:00+00:00...\n",
      "Crawling from 2019-08-04 00:00:00+00:00 to 2019-08-05 00:00:00+00:00...\n",
      "Crawling from 2019-08-03 00:00:00+00:00 to 2019-08-04 00:00:00+00:00...\n",
      "Crawling from 2019-08-02 00:00:00+00:00 to 2019-08-03 00:00:00+00:00...\n",
      "Crawling from 2019-08-01 00:00:00+00:00 to 2019-08-02 00:00:00+00:00...\n",
      "Crawling from 2019-07-31 00:00:00+00:00 to 2019-08-01 00:00:00+00:00...\n",
      "Crawling from 2019-07-30 00:00:00+00:00 to 2019-07-31 00:00:00+00:00...\n",
      "Crawling from 2019-07-29 00:00:00+00:00 to 2019-07-30 00:00:00+00:00...\n",
      "Crawling from 2019-07-28 00:00:00+00:00 to 2019-07-29 00:00:00+00:00...\n",
      "Crawling from 2019-07-27 00:00:00+00:00 to 2019-07-28 00:00:00+00:00...\n",
      "Crawling from 2019-07-26 00:00:00+00:00 to 2019-07-27 00:00:00+00:00...\n",
      "Crawling from 2019-07-25 00:00:00+00:00 to 2019-07-26 00:00:00+00:00...\n",
      "Crawling from 2019-07-24 00:00:00+00:00 to 2019-07-25 00:00:00+00:00...\n",
      "Crawling from 2019-07-23 00:00:00+00:00 to 2019-07-24 00:00:00+00:00...\n",
      "Crawling from 2019-07-22 00:00:00+00:00 to 2019-07-23 00:00:00+00:00...\n",
      "Crawling from 2019-07-21 00:00:00+00:00 to 2019-07-22 00:00:00+00:00...\n",
      "Crawling from 2019-07-20 00:00:00+00:00 to 2019-07-21 00:00:00+00:00...\n",
      "Crawling from 2019-07-19 00:00:00+00:00 to 2019-07-20 00:00:00+00:00...\n",
      "Crawling from 2019-07-18 00:00:00+00:00 to 2019-07-19 00:00:00+00:00...\n",
      "Crawling from 2019-07-17 00:00:00+00:00 to 2019-07-18 00:00:00+00:00...\n",
      "Crawling from 2019-07-16 00:00:00+00:00 to 2019-07-17 00:00:00+00:00...\n",
      "Crawling from 2019-07-15 00:00:00+00:00 to 2019-07-16 00:00:00+00:00...\n",
      "Crawling from 2019-07-14 00:00:00+00:00 to 2019-07-15 00:00:00+00:00...\n",
      "Crawling from 2019-07-13 00:00:00+00:00 to 2019-07-14 00:00:00+00:00...\n",
      "Crawling from 2019-07-12 00:00:00+00:00 to 2019-07-13 00:00:00+00:00...\n",
      "Crawling from 2019-07-11 00:00:00+00:00 to 2019-07-12 00:00:00+00:00...\n",
      "Crawling from 2019-07-10 00:00:00+00:00 to 2019-07-11 00:00:00+00:00...\n",
      "Crawling from 2019-07-09 00:00:00+00:00 to 2019-07-10 00:00:00+00:00...\n",
      "Crawling from 2019-07-08 00:00:00+00:00 to 2019-07-09 00:00:00+00:00...\n",
      "Crawling from 2019-07-07 00:00:00+00:00 to 2019-07-08 00:00:00+00:00...\n",
      "Crawling from 2019-07-06 00:00:00+00:00 to 2019-07-07 00:00:00+00:00...\n",
      "Crawling from 2019-07-05 00:00:00+00:00 to 2019-07-06 00:00:00+00:00...\n",
      "Crawling from 2019-07-04 00:00:00+00:00 to 2019-07-05 00:00:00+00:00...\n",
      "Crawling from 2019-07-03 00:00:00+00:00 to 2019-07-04 00:00:00+00:00...\n",
      "Crawling from 2019-07-02 00:00:00+00:00 to 2019-07-03 00:00:00+00:00...\n",
      "Crawling from 2019-07-01 00:00:00+00:00 to 2019-07-02 00:00:00+00:00...\n",
      "Crawling from 2019-06-30 00:00:00+00:00 to 2019-07-01 00:00:00+00:00...\n",
      "Crawling from 2019-06-29 00:00:00+00:00 to 2019-06-30 00:00:00+00:00...\n",
      "Crawling from 2019-06-28 00:00:00+00:00 to 2019-06-29 00:00:00+00:00...\n",
      "Crawling from 2019-06-27 00:00:00+00:00 to 2019-06-28 00:00:00+00:00...\n",
      "Crawling from 2019-06-26 00:00:00+00:00 to 2019-06-27 00:00:00+00:00...\n",
      "Crawling from 2019-06-25 00:00:00+00:00 to 2019-06-26 00:00:00+00:00...\n",
      "Crawling from 2019-06-24 00:00:00+00:00 to 2019-06-25 00:00:00+00:00...\n",
      "Crawling from 2019-06-23 00:00:00+00:00 to 2019-06-24 00:00:00+00:00...\n",
      "Crawling from 2019-06-22 00:00:00+00:00 to 2019-06-23 00:00:00+00:00...\n",
      "Crawling from 2019-06-21 00:00:00+00:00 to 2019-06-22 00:00:00+00:00...\n",
      "Crawling from 2019-06-20 00:00:00+00:00 to 2019-06-21 00:00:00+00:00...\n",
      "Crawling from 2019-06-19 00:00:00+00:00 to 2019-06-20 00:00:00+00:00...\n",
      "Crawling from 2019-06-18 00:00:00+00:00 to 2019-06-19 00:00:00+00:00...\n",
      "Crawling from 2019-06-17 00:00:00+00:00 to 2019-06-18 00:00:00+00:00...\n",
      "Crawling from 2019-06-16 00:00:00+00:00 to 2019-06-17 00:00:00+00:00...\n",
      "Crawling from 2019-06-15 00:00:00+00:00 to 2019-06-16 00:00:00+00:00...\n",
      "Crawling from 2019-06-14 00:00:00+00:00 to 2019-06-15 00:00:00+00:00...\n",
      "Crawling from 2019-06-13 00:00:00+00:00 to 2019-06-14 00:00:00+00:00...\n",
      "Crawling from 2019-06-12 00:00:00+00:00 to 2019-06-13 00:00:00+00:00...\n",
      "Crawling from 2019-06-11 00:00:00+00:00 to 2019-06-12 00:00:00+00:00...\n",
      "Crawling from 2019-06-10 00:00:00+00:00 to 2019-06-11 00:00:00+00:00...\n",
      "Crawling from 2019-06-09 00:00:00+00:00 to 2019-06-10 00:00:00+00:00...\n",
      "Crawling from 2019-06-08 00:00:00+00:00 to 2019-06-09 00:00:00+00:00...\n",
      "Crawling from 2019-06-07 00:00:00+00:00 to 2019-06-08 00:00:00+00:00...\n",
      "Crawling from 2019-06-06 00:00:00+00:00 to 2019-06-07 00:00:00+00:00...\n",
      "Crawling from 2019-06-05 00:00:00+00:00 to 2019-06-06 00:00:00+00:00...\n",
      "Crawling from 2019-06-04 00:00:00+00:00 to 2019-06-05 00:00:00+00:00...\n",
      "Crawling from 2019-06-03 00:00:00+00:00 to 2019-06-04 00:00:00+00:00...\n",
      "Crawling from 2019-06-02 00:00:00+00:00 to 2019-06-03 00:00:00+00:00...\n",
      "Crawling from 2019-06-01 00:00:00+00:00 to 2019-06-02 00:00:00+00:00...\n",
      "Crawling from 2019-05-31 00:00:00+00:00 to 2019-06-01 00:00:00+00:00...\n",
      "Crawling from 2019-05-30 00:00:00+00:00 to 2019-05-31 00:00:00+00:00...\n",
      "Crawling from 2019-05-29 00:00:00+00:00 to 2019-05-30 00:00:00+00:00...\n",
      "Crawling from 2019-05-28 00:00:00+00:00 to 2019-05-29 00:00:00+00:00...\n",
      "Crawling from 2019-05-27 00:00:00+00:00 to 2019-05-28 00:00:00+00:00...\n",
      "Crawling from 2019-05-26 00:00:00+00:00 to 2019-05-27 00:00:00+00:00...\n",
      "Crawling from 2019-05-25 00:00:00+00:00 to 2019-05-26 00:00:00+00:00...\n",
      "Crawling from 2019-05-24 00:00:00+00:00 to 2019-05-25 00:00:00+00:00...\n",
      "Crawling from 2019-05-23 00:00:00+00:00 to 2019-05-24 00:00:00+00:00...\n",
      "Crawling from 2019-05-22 00:00:00+00:00 to 2019-05-23 00:00:00+00:00...\n",
      "Crawling from 2019-05-21 00:00:00+00:00 to 2019-05-22 00:00:00+00:00...\n",
      "Crawling from 2019-05-20 00:00:00+00:00 to 2019-05-21 00:00:00+00:00...\n",
      "Crawling from 2019-05-19 00:00:00+00:00 to 2019-05-20 00:00:00+00:00...\n",
      "Crawling from 2019-05-18 00:00:00+00:00 to 2019-05-19 00:00:00+00:00...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling from 2019-05-17 00:00:00+00:00 to 2019-05-18 00:00:00+00:00...\n",
      "Crawling from 2019-05-16 00:00:00+00:00 to 2019-05-17 00:00:00+00:00...\n",
      "Crawling from 2019-05-15 00:00:00+00:00 to 2019-05-16 00:00:00+00:00...\n",
      "Crawling from 2019-05-14 00:00:00+00:00 to 2019-05-15 00:00:00+00:00...\n",
      "Crawling from 2019-05-13 00:00:00+00:00 to 2019-05-14 00:00:00+00:00...\n",
      "Crawling from 2019-05-12 00:00:00+00:00 to 2019-05-13 00:00:00+00:00...\n",
      "Crawling from 2019-05-11 00:00:00+00:00 to 2019-05-12 00:00:00+00:00...\n",
      "Crawling from 2019-05-10 00:00:00+00:00 to 2019-05-11 00:00:00+00:00...\n",
      "Crawling from 2019-05-09 00:00:00+00:00 to 2019-05-10 00:00:00+00:00...\n",
      "Crawling from 2019-05-08 00:00:00+00:00 to 2019-05-09 00:00:00+00:00...\n",
      "Crawling from 2019-05-07 00:00:00+00:00 to 2019-05-08 00:00:00+00:00...\n",
      "Crawling from 2019-05-06 00:00:00+00:00 to 2019-05-07 00:00:00+00:00...\n",
      "Crawling from 2019-05-05 00:00:00+00:00 to 2019-05-06 00:00:00+00:00...\n",
      "Crawling from 2019-05-04 00:00:00+00:00 to 2019-05-05 00:00:00+00:00...\n",
      "Crawling from 2019-05-03 00:00:00+00:00 to 2019-05-04 00:00:00+00:00...\n",
      "Crawling from 2019-05-02 00:00:00+00:00 to 2019-05-03 00:00:00+00:00...\n",
      "Crawling from 2019-05-01 00:00:00+00:00 to 2019-05-02 00:00:00+00:00...\n",
      "Crawling from 2019-04-30 00:00:00+00:00 to 2019-05-01 00:00:00+00:00...\n",
      "Crawling from 2019-04-29 00:00:00+00:00 to 2019-04-30 00:00:00+00:00...\n",
      "Crawling from 2019-04-28 00:00:00+00:00 to 2019-04-29 00:00:00+00:00...\n",
      "Crawling from 2019-04-27 00:00:00+00:00 to 2019-04-28 00:00:00+00:00...\n",
      "Crawling from 2019-04-26 00:00:00+00:00 to 2019-04-27 00:00:00+00:00...\n",
      "Crawling from 2019-04-25 00:00:00+00:00 to 2019-04-26 00:00:00+00:00...\n",
      "Crawling from 2019-04-24 00:00:00+00:00 to 2019-04-25 00:00:00+00:00...\n",
      "Crawling from 2019-04-23 00:00:00+00:00 to 2019-04-24 00:00:00+00:00...\n",
      "Crawling from 2019-04-22 00:00:00+00:00 to 2019-04-23 00:00:00+00:00...\n",
      "Crawling from 2019-04-21 00:00:00+00:00 to 2019-04-22 00:00:00+00:00...\n",
      "Crawling from 2019-04-20 00:00:00+00:00 to 2019-04-21 00:00:00+00:00...\n",
      "Crawling from 2019-04-19 00:00:00+00:00 to 2019-04-20 00:00:00+00:00...\n",
      "Crawling from 2019-04-18 00:00:00+00:00 to 2019-04-19 00:00:00+00:00...\n",
      "Crawling from 2019-04-17 00:00:00+00:00 to 2019-04-18 00:00:00+00:00...\n",
      "Crawling from 2019-04-16 00:00:00+00:00 to 2019-04-17 00:00:00+00:00...\n",
      "Crawling from 2019-04-15 00:00:00+00:00 to 2019-04-16 00:00:00+00:00...\n",
      "Crawling from 2019-04-14 00:00:00+00:00 to 2019-04-15 00:00:00+00:00...\n",
      "Crawling from 2019-04-13 00:00:00+00:00 to 2019-04-14 00:00:00+00:00...\n",
      "Crawling from 2019-04-12 00:00:00+00:00 to 2019-04-13 00:00:00+00:00...\n",
      "Crawling from 2019-04-11 00:00:00+00:00 to 2019-04-12 00:00:00+00:00...\n",
      "Crawling from 2019-04-10 00:00:00+00:00 to 2019-04-11 00:00:00+00:00...\n",
      "Crawling from 2019-04-09 00:00:00+00:00 to 2019-04-10 00:00:00+00:00...\n",
      "Crawling from 2019-04-08 00:00:00+00:00 to 2019-04-09 00:00:00+00:00...\n",
      "Crawling from 2019-04-07 00:00:00+00:00 to 2019-04-08 00:00:00+00:00...\n",
      "Crawling from 2019-04-06 00:00:00+00:00 to 2019-04-07 00:00:00+00:00...\n",
      "Crawling from 2019-04-05 00:00:00+00:00 to 2019-04-06 00:00:00+00:00...\n",
      "Crawling from 2019-04-04 00:00:00+00:00 to 2019-04-05 00:00:00+00:00...\n",
      "Crawling from 2019-04-03 00:00:00+00:00 to 2019-04-04 00:00:00+00:00...\n",
      "Crawling from 2019-04-02 00:00:00+00:00 to 2019-04-03 00:00:00+00:00...\n",
      "Crawling from 2019-04-01 00:00:00+00:00 to 2019-04-02 00:00:00+00:00...\n",
      "Crawling from 2019-03-31 00:00:00+00:00 to 2019-04-01 00:00:00+00:00...\n",
      "Crawling from 2019-03-30 00:00:00+00:00 to 2019-03-31 00:00:00+00:00...\n",
      "Crawling from 2019-03-29 00:00:00+00:00 to 2019-03-30 00:00:00+00:00...\n",
      "Crawling from 2019-03-28 00:00:00+00:00 to 2019-03-29 00:00:00+00:00...\n",
      "Crawling from 2019-03-27 00:00:00+00:00 to 2019-03-28 00:00:00+00:00...\n",
      "Crawling from 2019-03-26 00:00:00+00:00 to 2019-03-27 00:00:00+00:00...\n",
      "Crawling from 2019-03-25 00:00:00+00:00 to 2019-03-26 00:00:00+00:00...\n",
      "Crawling from 2019-03-24 00:00:00+00:00 to 2019-03-25 00:00:00+00:00...\n",
      "Crawling from 2019-03-23 00:00:00+00:00 to 2019-03-24 00:00:00+00:00...\n",
      "Crawling from 2019-03-22 00:00:00+00:00 to 2019-03-23 00:00:00+00:00...\n",
      "Crawling from 2019-03-21 00:00:00+00:00 to 2019-03-22 00:00:00+00:00...\n",
      "Crawling from 2019-03-20 00:00:00+00:00 to 2019-03-21 00:00:00+00:00...\n",
      "Crawling from 2019-03-19 00:00:00+00:00 to 2019-03-20 00:00:00+00:00...\n",
      "Crawling from 2019-03-18 00:00:00+00:00 to 2019-03-19 00:00:00+00:00...\n",
      "Crawling from 2019-03-17 00:00:00+00:00 to 2019-03-18 00:00:00+00:00...\n",
      "Crawling from 2019-03-16 00:00:00+00:00 to 2019-03-17 00:00:00+00:00...\n",
      "Crawling from 2019-03-15 00:00:00+00:00 to 2019-03-16 00:00:00+00:00...\n",
      "Crawling from 2019-03-14 00:00:00+00:00 to 2019-03-15 00:00:00+00:00...\n",
      "Crawling from 2019-03-13 00:00:00+00:00 to 2019-03-14 00:00:00+00:00...\n",
      "Crawling from 2019-03-12 00:00:00+00:00 to 2019-03-13 00:00:00+00:00...\n",
      "Crawling from 2019-03-11 00:00:00+00:00 to 2019-03-12 00:00:00+00:00...\n",
      "Crawling from 2019-03-10 00:00:00+00:00 to 2019-03-11 00:00:00+00:00...\n",
      "Crawling from 2019-03-09 00:00:00+00:00 to 2019-03-10 00:00:00+00:00...\n",
      "Crawling from 2019-03-08 00:00:00+00:00 to 2019-03-09 00:00:00+00:00...\n",
      "Crawling from 2019-03-07 00:00:00+00:00 to 2019-03-08 00:00:00+00:00...\n",
      "Crawling from 2019-03-06 00:00:00+00:00 to 2019-03-07 00:00:00+00:00...\n",
      "Crawling from 2019-03-05 00:00:00+00:00 to 2019-03-06 00:00:00+00:00...\n",
      "Crawling from 2019-03-04 00:00:00+00:00 to 2019-03-05 00:00:00+00:00...\n",
      "Crawling from 2019-03-03 00:00:00+00:00 to 2019-03-04 00:00:00+00:00...\n",
      "Crawling from 2019-03-02 00:00:00+00:00 to 2019-03-03 00:00:00+00:00...\n",
      "Crawling from 2019-03-01 00:00:00+00:00 to 2019-03-02 00:00:00+00:00...\n",
      "Crawling from 2019-02-28 00:00:00+00:00 to 2019-03-01 00:00:00+00:00...\n",
      "Crawling from 2019-02-27 00:00:00+00:00 to 2019-02-28 00:00:00+00:00...\n",
      "Crawling from 2019-02-26 00:00:00+00:00 to 2019-02-27 00:00:00+00:00...\n",
      "Crawling from 2019-02-25 00:00:00+00:00 to 2019-02-26 00:00:00+00:00...\n",
      "Crawling from 2019-02-24 00:00:00+00:00 to 2019-02-25 00:00:00+00:00...\n",
      "Crawling from 2019-02-23 00:00:00+00:00 to 2019-02-24 00:00:00+00:00...\n",
      "Crawling from 2019-02-22 00:00:00+00:00 to 2019-02-23 00:00:00+00:00...\n",
      "Crawling from 2019-02-21 00:00:00+00:00 to 2019-02-22 00:00:00+00:00...\n",
      "Crawling from 2019-02-20 00:00:00+00:00 to 2019-02-21 00:00:00+00:00...\n",
      "Crawling from 2019-02-19 00:00:00+00:00 to 2019-02-20 00:00:00+00:00...\n",
      "Crawling from 2019-02-18 00:00:00+00:00 to 2019-02-19 00:00:00+00:00...\n",
      "Crawling from 2019-02-17 00:00:00+00:00 to 2019-02-18 00:00:00+00:00...\n"
     ]
    }
   ],
   "source": [
    "current_timestamp = end_timestamp\n",
    "url = 'https://api.pushshift.io/reddit/search/submission/'\n",
    "while current_timestamp > start_timestamp:\n",
    "    if (current_timestamp - end_timestamp) % 86400 == 0:\n",
    "        date_1 = datetime.fromtimestamp(current_timestamp - 86400, timezone.utc)\n",
    "        date_2 = datetime.fromtimestamp(current_timestamp, timezone.utc)\n",
    "        print('Crawling from {} to {}...'.format(date_1, date_2))\n",
    "    params = {\n",
    "        'subreddit': 'TodayIamHappy',\n",
    "        'sort': 'desc',\n",
    "        'sort_type': 'created_utc',\n",
    "        'after': str(int(current_timestamp - 3600 - 1)),\n",
    "        'before': str(int(current_timestamp)),\n",
    "        'size': '100'\n",
    "    }\n",
    "    res = requests.get(url, params = params)\n",
    "    if is_json(res.text):\n",
    "        submissions = res.json()['data']\n",
    "        for submission in submissions:\n",
    "\n",
    "            all_cols_exist = True\n",
    "            for col in submission_cols:\n",
    "                if col not in submission:\n",
    "                    all_cols_exist = False\n",
    "                    break\n",
    "            if not all_cols_exist:\n",
    "                continue\n",
    "\n",
    "            for col in submission_cols:\n",
    "                submission_dict[col].append(submission[col])\n",
    "\n",
    "            for col in submission_cols_opt:\n",
    "                if col in submission:\n",
    "                    submission_dict[col].append(submission[col])\n",
    "                else:\n",
    "                    submission_dict[col].append(None)\n",
    "\n",
    "    current_timestamp = current_timestamp - 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 367\n"
     ]
    }
   ],
   "source": [
    "print(len(submission_dict['id']), len(set(submission_dict['id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>score</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>link_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ei81i5</td>\n",
       "      <td>1577822644</td>\n",
       "      <td>TIAH because I did the things</td>\n",
       "      <td>I ended the year not quite as I wanted, but I ...</td>\n",
       "      <td>6</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_51bsneye</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>egvfeg</td>\n",
       "      <td>1577563391</td>\n",
       "      <td>TIAH because I cleaned my room</td>\n",
       "      <td>Got up at four this morning, looked at the tim...</td>\n",
       "      <td>6</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_11m7hi</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egtsrb</td>\n",
       "      <td>1577555820</td>\n",
       "      <td>TIAH because I finally moved into a house by m...</td>\n",
       "      <td>After years of living in flat shares and with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_5azviqqo</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>egjt92</td>\n",
       "      <td>1577494779</td>\n",
       "      <td>TIAH because I ordered all of my new computers...</td>\n",
       "      <td>I have been saving for 6 months now, and with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_kpxl5yo</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eg4br3</td>\n",
       "      <td>1577410404</td>\n",
       "      <td>TIAH because I just took my first real shower ...</td>\n",
       "      <td>I was treated for cancer this year, and since ...</td>\n",
       "      <td>8</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_1i4vkuhe</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>aruiw3</td>\n",
       "      <td>1550473579</td>\n",
       "      <td>Today my cat was stretchy and it made me happy.</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_2uhdzwod</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>arnxir</td>\n",
       "      <td>1550431269</td>\n",
       "      <td>TIAH because i had a wonderful hike up the hil...</td>\n",
       "      <td>Spending my time in the nature always makes me...</td>\n",
       "      <td>5</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>15</td>\n",
       "      <td>t2_33zpmhq8</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>arnkvr</td>\n",
       "      <td>1550429358</td>\n",
       "      <td>TIAH because I found this subreddit.</td>\n",
       "      <td>Is it okay to use this as sort of a gratitude ...</td>\n",
       "      <td>2</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>28</td>\n",
       "      <td>t2_2xa30jei</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>arjz1k</td>\n",
       "      <td>1550404992</td>\n",
       "      <td>TIAH because I started a new subreddit and hop...</td>\n",
       "      <td>It was not planned. It just struck my mind and...</td>\n",
       "      <td>0</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>50</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>arjfjj</td>\n",
       "      <td>1550399473</td>\n",
       "      <td>TIAH because I started a new subreddit and hop...</td>\n",
       "      <td>It was not planned. It just struck my mind and...</td>\n",
       "      <td>1</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  created_utc                                              title  \\\n",
       "0    ei81i5   1577822644                      TIAH because I did the things   \n",
       "1    egvfeg   1577563391                     TIAH because I cleaned my room   \n",
       "2    egtsrb   1577555820  TIAH because I finally moved into a house by m...   \n",
       "3    egjt92   1577494779  TIAH because I ordered all of my new computers...   \n",
       "4    eg4br3   1577410404  TIAH because I just took my first real shower ...   \n",
       "..      ...          ...                                                ...   \n",
       "362  aruiw3   1550473579    Today my cat was stretchy and it made me happy.   \n",
       "363  arnxir   1550431269  TIAH because i had a wonderful hike up the hil...   \n",
       "364  arnkvr   1550429358               TIAH because I found this subreddit.   \n",
       "365  arjz1k   1550404992  TIAH because I started a new subreddit and hop...   \n",
       "366  arjfjj   1550399473  TIAH because I started a new subreddit and hop...   \n",
       "\n",
       "                                              selftext  num_comments  \\\n",
       "0    I ended the year not quite as I wanted, but I ...             6   \n",
       "1    Got up at four this morning, looked at the tim...             6   \n",
       "2    After years of living in flat shares and with ...             5   \n",
       "3    I have been saving for 6 months now, and with ...             5   \n",
       "4    I was treated for cancer this year, and since ...             8   \n",
       "..                                                 ...           ...   \n",
       "362                                                                0   \n",
       "363  Spending my time in the nature always makes me...             5   \n",
       "364  Is it okay to use this as sort of a gratitude ...             2   \n",
       "365  It was not planned. It just struck my mind and...             0   \n",
       "366  It was not planned. It just struck my mind and...             1   \n",
       "\n",
       "         subreddit subreddit_id  score author_fullname link_flair_text  \n",
       "0    TodayIamHappy     t5_wpspv      1     t2_51bsneye               S  \n",
       "1    TodayIamHappy     t5_wpspv      1       t2_11m7hi               S  \n",
       "2    TodayIamHappy     t5_wpspv      1     t2_5azviqqo               S  \n",
       "3    TodayIamHappy     t5_wpspv      1      t2_kpxl5yo            None  \n",
       "4    TodayIamHappy     t5_wpspv      1     t2_1i4vkuhe               M  \n",
       "..             ...          ...    ...             ...             ...  \n",
       "362  TodayIamHappy     t5_wpspv      1     t2_2uhdzwod            None  \n",
       "363  TodayIamHappy     t5_wpspv     15     t2_33zpmhq8            None  \n",
       "364  TodayIamHappy     t5_wpspv     28     t2_2xa30jei            None  \n",
       "365  TodayIamHappy     t5_wpspv     50     t2_38ppbu69            None  \n",
       "366  TodayIamHappy     t5_wpspv      1     t2_38ppbu69            None  \n",
       "\n",
       "[367 rows x 10 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('pushshift/tiah_submissions_20190217_20191231.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl Comments According to the Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('pushshift/tiah_submissions_20190217_20191231.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>score</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>link_flair_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ei81i5</td>\n",
       "      <td>1577822644</td>\n",
       "      <td>TIAH because I did the things</td>\n",
       "      <td>I ended the year not quite as I wanted, but I ...</td>\n",
       "      <td>6</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_51bsneye</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>egvfeg</td>\n",
       "      <td>1577563391</td>\n",
       "      <td>TIAH because I cleaned my room</td>\n",
       "      <td>Got up at four this morning, looked at the tim...</td>\n",
       "      <td>6</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_11m7hi</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egtsrb</td>\n",
       "      <td>1577555820</td>\n",
       "      <td>TIAH because I finally moved into a house by m...</td>\n",
       "      <td>After years of living in flat shares and with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_5azviqqo</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>egjt92</td>\n",
       "      <td>1577494779</td>\n",
       "      <td>TIAH because I ordered all of my new computers...</td>\n",
       "      <td>I have been saving for 6 months now, and with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_kpxl5yo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eg4br3</td>\n",
       "      <td>1577410404</td>\n",
       "      <td>TIAH because I just took my first real shower ...</td>\n",
       "      <td>I was treated for cancer this year, and since ...</td>\n",
       "      <td>8</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_1i4vkuhe</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>aruiw3</td>\n",
       "      <td>1550473579</td>\n",
       "      <td>Today my cat was stretchy and it made me happy.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_2uhdzwod</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>arnxir</td>\n",
       "      <td>1550431269</td>\n",
       "      <td>TIAH because i had a wonderful hike up the hil...</td>\n",
       "      <td>Spending my time in the nature always makes me...</td>\n",
       "      <td>5</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>15</td>\n",
       "      <td>t2_33zpmhq8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>arnkvr</td>\n",
       "      <td>1550429358</td>\n",
       "      <td>TIAH because I found this subreddit.</td>\n",
       "      <td>Is it okay to use this as sort of a gratitude ...</td>\n",
       "      <td>2</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>28</td>\n",
       "      <td>t2_2xa30jei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>arjz1k</td>\n",
       "      <td>1550404992</td>\n",
       "      <td>TIAH because I started a new subreddit and hop...</td>\n",
       "      <td>It was not planned. It just struck my mind and...</td>\n",
       "      <td>0</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>50</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>arjfjj</td>\n",
       "      <td>1550399473</td>\n",
       "      <td>TIAH because I started a new subreddit and hop...</td>\n",
       "      <td>It was not planned. It just struck my mind and...</td>\n",
       "      <td>1</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  created_utc                                              title  \\\n",
       "0    ei81i5   1577822644                      TIAH because I did the things   \n",
       "1    egvfeg   1577563391                     TIAH because I cleaned my room   \n",
       "2    egtsrb   1577555820  TIAH because I finally moved into a house by m...   \n",
       "3    egjt92   1577494779  TIAH because I ordered all of my new computers...   \n",
       "4    eg4br3   1577410404  TIAH because I just took my first real shower ...   \n",
       "..      ...          ...                                                ...   \n",
       "362  aruiw3   1550473579    Today my cat was stretchy and it made me happy.   \n",
       "363  arnxir   1550431269  TIAH because i had a wonderful hike up the hil...   \n",
       "364  arnkvr   1550429358               TIAH because I found this subreddit.   \n",
       "365  arjz1k   1550404992  TIAH because I started a new subreddit and hop...   \n",
       "366  arjfjj   1550399473  TIAH because I started a new subreddit and hop...   \n",
       "\n",
       "                                              selftext  num_comments  \\\n",
       "0    I ended the year not quite as I wanted, but I ...             6   \n",
       "1    Got up at four this morning, looked at the tim...             6   \n",
       "2    After years of living in flat shares and with ...             5   \n",
       "3    I have been saving for 6 months now, and with ...             5   \n",
       "4    I was treated for cancer this year, and since ...             8   \n",
       "..                                                 ...           ...   \n",
       "362                                                NaN             0   \n",
       "363  Spending my time in the nature always makes me...             5   \n",
       "364  Is it okay to use this as sort of a gratitude ...             2   \n",
       "365  It was not planned. It just struck my mind and...             0   \n",
       "366  It was not planned. It just struck my mind and...             1   \n",
       "\n",
       "         subreddit subreddit_id  score author_fullname link_flair_text  \n",
       "0    TodayIamHappy     t5_wpspv      1     t2_51bsneye               S  \n",
       "1    TodayIamHappy     t5_wpspv      1       t2_11m7hi               S  \n",
       "2    TodayIamHappy     t5_wpspv      1     t2_5azviqqo               S  \n",
       "3    TodayIamHappy     t5_wpspv      1      t2_kpxl5yo             NaN  \n",
       "4    TodayIamHappy     t5_wpspv      1     t2_1i4vkuhe               M  \n",
       "..             ...          ...    ...             ...             ...  \n",
       "362  TodayIamHappy     t5_wpspv      1     t2_2uhdzwod             NaN  \n",
       "363  TodayIamHappy     t5_wpspv     15     t2_33zpmhq8             NaN  \n",
       "364  TodayIamHappy     t5_wpspv     28     t2_2xa30jei             NaN  \n",
       "365  TodayIamHappy     t5_wpspv     50     t2_38ppbu69             NaN  \n",
       "366  TodayIamHappy     t5_wpspv      1     t2_38ppbu69             NaN  \n",
       "\n",
       "[367 rows x 10 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_json(json_data):\n",
    "    try:\n",
    "        json_object = json.loads(json_data)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 367/367 [09:56<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(submission_df.shape[0])):\n",
    "    submission_id = submission_df.iloc[i]['id']\n",
    "    url = 'https://api.pushshift.io/reddit/submission/comment_ids/{}'.format(submission_id)\n",
    "    res = requests.get(url)\n",
    "    if is_json(res.text):\n",
    "        comment_ids += res.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': comment_ids}).to_csv('pushshift/tiah_comment_ids_20190217_20191231.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue crawling the comment ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dc76tfw',\n",
       " 'dd1cdhv',\n",
       " 'dbx20a3',\n",
       " 'dc6qxsl',\n",
       " 'dcosxo6',\n",
       " 'dcow3f7',\n",
       " 'dc5dmfn',\n",
       " 'dcq5plm',\n",
       " 'dc08ifx',\n",
       " 'dbz8074']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_ids[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['djp74h6', 'djp7bjg', 'djp7pzm', 'djp8srl', 'djp9wz0', 'djpac3w', 'djpag5e', 'djpakig', 'djpasvb', 'djpax12', 'djpb54f', 'djpb6rz', 'djpb7h7', 'djpbcl5', 'djpbqrm', 'djpbyrl', 'djpcceq', 'djpd9e4']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.pushshift.io/reddit/submission/comment_ids/{}'.format(submission_df.iloc[26182+9702]['id'])\n",
    "res = requests.get(url)\n",
    "print(res.json()['data'])\n",
    "for i in res.json()['data']:\n",
    "    if i in comment_ids:\n",
    "        print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['djp7nh2',\n",
       " 'djp7qbn',\n",
       " 'djp7t1v',\n",
       " 'djp7xyd',\n",
       " 'djp7yfs',\n",
       " 'djp81zg',\n",
       " 'djp82el',\n",
       " 'djp83ct',\n",
       " 'djp8xdp',\n",
       " 'djp9hkd',\n",
       " 'djpa0z3',\n",
       " 'djpeu2c']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://api.pushshift.io/reddit/submission/comment_ids/{}'.format(submission_df.iloc[26182+9701]['id'])\n",
    "res = requests.get(url)\n",
    "res.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 19659/19659 [12:21:52<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(26182+9702, submission_df.shape[0])):\n",
    "    submission_id = submission_df.iloc[i]['id']\n",
    "    url = 'https://api.pushshift.io/reddit/submission/comment_ids/{}'.format(submission_id)\n",
    "    res = requests.get(url)\n",
    "    if is_json(res.text):\n",
    "        comment_ids += res.json()['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1017407"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'id': comment_ids}).to_csv('pushshift/casual_conv_comment_ids_20170101_20171231.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_cols = ['id', 'link_id', 'parent_id', 'created_utc', 'body', 'subreddit', 'subreddit_id']\n",
    "comment_cols_opt = ['score', 'author_fullname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_dict = {col: [] for col in comment_cols + comment_cols_opt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_comments(comment_query):\n",
    "    url = 'https://api.pushshift.io/reddit/comment/search?ids={}'.format(comment_query)\n",
    "    res = requests.get(url)\n",
    "    if not is_json(res.text):\n",
    "        return\n",
    "    comments = res.json()['data']\n",
    "\n",
    "    for comment in comments:\n",
    "        all_cols_exist = True\n",
    "        for col in comment_cols:\n",
    "            if col not in comment:\n",
    "                all_cols_exist = False\n",
    "                break\n",
    "        if not all_cols_exist:\n",
    "            continue\n",
    "\n",
    "        for col in comment_cols:\n",
    "            comment_dict[col].append(comment[col])\n",
    "\n",
    "        for col in comment_cols_opt:\n",
    "            if col in comment:\n",
    "                comment_dict[col].append(comment[col])\n",
    "            else:\n",
    "                comment_dict[col].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.48s/it]\n"
     ]
    }
   ],
   "source": [
    "N = len(comment_ids)\n",
    "batch_size = 1000\n",
    "num_batches = N // batch_size\n",
    "\n",
    "for batch in tqdm(range(num_batches)):\n",
    "    s = batch * batch_size\n",
    "    t = s + batch_size\n",
    "    comment_query = ','.join(comment_ids[s:t])\n",
    "    crawl_comments(comment_query)\n",
    "\n",
    "if N % batch_size != 0:\n",
    "    comment_query = ','.join(comment_ids[(num_batches*batch_size):N])\n",
    "    crawl_comments(comment_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.DataFrame(comment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>score</th>\n",
       "      <th>author_fullname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>egt9ff5</td>\n",
       "      <td>t3_ascdt2</td>\n",
       "      <td>t3_ascdt2</td>\n",
       "      <td>1550595672</td>\n",
       "      <td>Well if you want someone to talk with then a u...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>egtarex</td>\n",
       "      <td>t3_ascdt2</td>\n",
       "      <td>t3_ascdt2</td>\n",
       "      <td>1550596566</td>\n",
       "      <td>That’s amazing, I’m happy to hear that!\\n\\nPer...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_2zzephhe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egtdz98</td>\n",
       "      <td>t3_ascxas</td>\n",
       "      <td>t3_ascxas</td>\n",
       "      <td>1550598658</td>\n",
       "      <td>Thanks for your appreciation. But honestly, al...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>egthkeq</td>\n",
       "      <td>t3_asdma1</td>\n",
       "      <td>t3_asdma1</td>\n",
       "      <td>1550600982</td>\n",
       "      <td>Thanks for submitting to r/TodayIamHappy /u/TI...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>egtiuck</td>\n",
       "      <td>t3_asdp8t</td>\n",
       "      <td>t3_asdp8t</td>\n",
       "      <td>1550601816</td>\n",
       "      <td>That is crazy! Let’s hope that some of them be...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_1k6wswle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>eguf1om</td>\n",
       "      <td>t3_as7flg</td>\n",
       "      <td>t1_egsc4ww</td>\n",
       "      <td>1550624408</td>\n",
       "      <td>Too bad its not a boy</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_aj9tc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>eguwrbv</td>\n",
       "      <td>t3_as71cl</td>\n",
       "      <td>t3_as71cl</td>\n",
       "      <td>1550638797</td>\n",
       "      <td>TIAH because this subreddit exists and people ...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_yjisnr0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>egux3y5</td>\n",
       "      <td>t3_as71cl</td>\n",
       "      <td>t1_eguwrbv</td>\n",
       "      <td>1550639145</td>\n",
       "      <td>It really makes me feel happy that people are ...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_38ppbu69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>egv5m5a</td>\n",
       "      <td>t3_as2bg0</td>\n",
       "      <td>t1_egsct01</td>\n",
       "      <td>1550649703</td>\n",
       "      <td>Thank you very much!\\n\\nSounds like it's simpl...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_33zpmhq8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>ejkglyz</td>\n",
       "      <td>t3_arnxir</td>\n",
       "      <td>t3_arnxir</td>\n",
       "      <td>1553775672</td>\n",
       "      <td>I am a gardener. I don't mean I really like to...</td>\n",
       "      <td>TodayIamHappy</td>\n",
       "      <td>t5_wpspv</td>\n",
       "      <td>1</td>\n",
       "      <td>t2_3gex1pwo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1105 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    link_id   parent_id  created_utc  \\\n",
       "0     egt9ff5  t3_ascdt2   t3_ascdt2   1550595672   \n",
       "1     egtarex  t3_ascdt2   t3_ascdt2   1550596566   \n",
       "2     egtdz98  t3_ascxas   t3_ascxas   1550598658   \n",
       "3     egthkeq  t3_asdma1   t3_asdma1   1550600982   \n",
       "4     egtiuck  t3_asdp8t   t3_asdp8t   1550601816   \n",
       "...       ...        ...         ...          ...   \n",
       "1100  eguf1om  t3_as7flg  t1_egsc4ww   1550624408   \n",
       "1101  eguwrbv  t3_as71cl   t3_as71cl   1550638797   \n",
       "1102  egux3y5  t3_as71cl  t1_eguwrbv   1550639145   \n",
       "1103  egv5m5a  t3_as2bg0  t1_egsct01   1550649703   \n",
       "1104  ejkglyz  t3_arnxir   t3_arnxir   1553775672   \n",
       "\n",
       "                                                   body      subreddit  \\\n",
       "0     Well if you want someone to talk with then a u...  TodayIamHappy   \n",
       "1     That’s amazing, I’m happy to hear that!\\n\\nPer...  TodayIamHappy   \n",
       "2     Thanks for your appreciation. But honestly, al...  TodayIamHappy   \n",
       "3     Thanks for submitting to r/TodayIamHappy /u/TI...  TodayIamHappy   \n",
       "4     That is crazy! Let’s hope that some of them be...  TodayIamHappy   \n",
       "...                                                 ...            ...   \n",
       "1100                              Too bad its not a boy  TodayIamHappy   \n",
       "1101  TIAH because this subreddit exists and people ...  TodayIamHappy   \n",
       "1102  It really makes me feel happy that people are ...  TodayIamHappy   \n",
       "1103  Thank you very much!\\n\\nSounds like it's simpl...  TodayIamHappy   \n",
       "1104  I am a gardener. I don't mean I really like to...  TodayIamHappy   \n",
       "\n",
       "     subreddit_id  score author_fullname  \n",
       "0        t5_wpspv      1     t2_38ppbu69  \n",
       "1        t5_wpspv      1     t2_2zzephhe  \n",
       "2        t5_wpspv      1     t2_38ppbu69  \n",
       "3        t5_wpspv      1        t2_6l4z3  \n",
       "4        t5_wpspv      1     t2_1k6wswle  \n",
       "...           ...    ...             ...  \n",
       "1100     t5_wpspv      1        t2_aj9tc  \n",
       "1101     t5_wpspv      1      t2_yjisnr0  \n",
       "1102     t5_wpspv      1     t2_38ppbu69  \n",
       "1103     t5_wpspv      1     t2_33zpmhq8  \n",
       "1104     t5_wpspv      1     t2_3gex1pwo  \n",
       "\n",
       "[1105 rows x 9 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df.to_csv('pushshift/tiah_comments_20190217_20191231.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
